{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0e5d0d-8e26-4278-a555-b4b5a30fd1e4",
   "metadata": {},
   "source": [
    "# Project A: Classifying Sentiment from Text Reviews\n",
    "In this project, our team will try to perfrom Bag of Word approch to implement sentiment clasificaion on product review on websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67146029-59b1-4d1c-95bf-067e34e15c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn.linear_model\n",
    "import sklearn.pipeline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import tokenize_text\n",
    "import cross_validation as cv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "from nltk.corpus import stopwords\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6355a07-f3ac-440c-a9b0-c5a31c576204",
   "metadata": {},
   "source": [
    "## Step1: Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2939be4d-8fa7-41db-82bd-290a23ee40c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     website_name                                               text\n",
      "0          amazon  Oh and I forgot to also mention the weird colo...\n",
      "1          amazon                       THAT one didn't work either.\n",
      "2          amazon                                 Waste of 13 bucks.\n",
      "3          amazon  Product is useless, since it does not have eno...\n",
      "4          amazon  None of the three sizes they sent with the hea...\n",
      "...           ...                                                ...\n",
      "2395         yelp  The sweet potato fries were very good and seas...\n",
      "2396         yelp  I could eat their bruschetta all day it is dev...\n",
      "2397         yelp                               Ambience is perfect.\n",
      "2398         yelp  We ordered the duck rare and it was pink and t...\n",
      "2399         yelp       Service was good and the company was better!\n",
      "\n",
      "[2400 rows x 2 columns]\n",
      "    website_name                                               text\n",
      "0         amazon  It only recognizes the Phone as its storage de...\n",
      "1         amazon  Disappointing accessory from a good manufacturer.\n",
      "2         amazon  The one big drawback of the MP3 player is that...\n",
      "3         amazon  This particular model would not work with my M...\n",
      "4         amazon  If the two were seperated by a mere 5+ ft I st...\n",
      "..           ...                                                ...\n",
      "595         yelp                Everything was fresh and delicious!\n",
      "596         yelp          - Really, really good rice, all the time.\n",
      "597         yelp                              Pretty awesome place.\n",
      "598         yelp        The staff are great, the ambiance is great.\n",
      "599         yelp            The patio seating was very comfortable.\n",
      "\n",
      "[600 rows x 2 columns]\n",
      "      is_positive_sentiment\n",
      "0                         0\n",
      "1                         0\n",
      "2                         0\n",
      "3                         0\n",
      "4                         0\n",
      "...                     ...\n",
      "2395                      1\n",
      "2396                      1\n",
      "2397                      1\n",
      "2398                      1\n",
      "2399                      1\n",
      "\n",
      "[2400 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# import datasets\n",
    "data_dir = 'data_reviews'\n",
    "x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "x_test_df = pd.read_csv(os.path.join(data_dir, 'x_test.csv'))\n",
    "y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "\n",
    "# debug you\n",
    "# printing out dataset\n",
    "print(x_train_df)\n",
    "print(x_test_df)\n",
    "print(y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c360262b-ddea-4497-8bbe-2bb383b81a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the first five rows and last five rows\n",
    "N, n_cols = x_train_df.shape\n",
    "# print(\"Shape of x_train_df: (%d, %d)\" % (N, n_cols))\n",
    "# print(\"Shape of y_train_df: %s\" % str(y_train_df.shape))\n",
    "\n",
    "# Print out the first five rows and last five rows\n",
    "tr_text_list = x_train_df['text'].values.tolist()\n",
    "\n",
    "test_text_list = x_test_df['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0051963c-50f9-4740-95f6-1e883eae3294",
   "metadata": {},
   "source": [
    "## Step2: Cleaning Imported Data and Count Vacabulary Friquency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d8101f-36ee-4d72-afff-c3c53484683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning raw data\n",
    "tok_count_dict = dict()\n",
    "for line in tr_text_list:\n",
    "    tok_list = tokenize_text.tokenize_text(line)\n",
    "    for tok in tok_list:\n",
    "        if tok in tok_count_dict:\n",
    "            tok_count_dict[tok] += 1\n",
    "        else:\n",
    "            tok_count_dict[tok] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a255ec-9c5a-4e13-9de1-1dc9528d1277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1560 the\n",
      "  916 and\n",
      "  707 a\n",
      "  700 i\n",
      "  609 is\n",
      "  542 to\n",
      "  534 it\n",
      "  493 of\n",
      "  493 this\n",
      "  447 was\n",
      "  328 in\n",
      "  271 \n",
      "  257 for\n",
      "  244 not\n",
      "  231 that\n",
      "  212 with\n",
      "  202 my\n",
      "  202 very\n",
      "  184 good\n",
      "  176 on\n",
      "  163 you\n",
      "  162 great\n",
      "  158 but\n",
      "  147 have\n",
      "  143 are\n",
      "  142 so\n",
      "  140 movie\n",
      "  137 phone\n",
      "  136 as\n",
      "  121 film\n",
      "  116 be\n",
      "  115 all\n",
      "  111 one\n",
      "  111 its\n",
      "  109 had\n",
      "  103 at\n",
      "  100 place\n",
      "   98 food\n",
      "   95 like\n",
      "   94 were\n",
      "   90 an\n",
      "   89 just\n",
      "   86 there\n",
      "   85 service\n",
      "   84 time\n",
      "   83 if\n",
      "   82 we\n",
      "   79 bad\n",
      "   79 really\n",
      "   78 out\n",
      "   76 they\n",
      "   76 from\n",
      "   75 would\n",
      "   71 well\n",
      "   70 about\n",
      "   69 has\n",
      "   66 your\n",
      "   65 dont\n",
      "   64 only\n",
      "   63 even\n",
      "   63 ever\n",
      "   63 best\n",
      "   62 by\n",
      "   62 back\n",
      "   62 or\n",
      "   59 here\n",
      "   57 also\n",
      "   57 will\n",
      "   56 no\n",
      "   54 up\n",
      "   53 go\n",
      "   52 than\n",
      "   51 me\n",
      "   51 quality\n",
      "   51 when\n",
      "   51 love\n",
      "   50 what\n",
      "   49 can\n",
      "   49 he\n",
      "   48 made\n",
      "   48 more\n",
      "   47 product\n",
      "   47 because\n",
      "   47 excellent\n",
      "   45 im\n",
      "   45 better\n",
      "   45 which\n",
      "   44 recommend\n",
      "   44 some\n",
      "   42 work\n",
      "   42 could\n",
      "   42 ive\n",
      "   42 get\n",
      "   42 too\n",
      "   42 works\n",
      "   42 his\n",
      "   41 been\n",
      "   41 how\n",
      "   41 who\n",
      "   41 our\n",
      "   40 use\n",
      "   40 did\n",
      "   40 after\n",
      "   40 much\n",
      "   40 again\n",
      "   39 headset\n",
      "   39 sound\n",
      "   39 make\n",
      "   39 do\n",
      "   39 nice\n",
      "   38 them\n",
      "   38 any\n",
      "   38 see\n",
      "   37 didnt\n",
      "   37 first\n",
      "   37 other\n",
      "   37 their\n",
      "   36 most\n",
      "   36 way\n",
      "   35 still\n",
      "   35 never\n",
      "   35 think\n",
      "   34 now\n",
      "   33 battery\n",
      "   32 disappointed\n",
      "   31 little\n",
      "   31 pretty\n",
      "   31 every\n",
      "   30 price\n",
      "   30 characters\n",
      "   30 acting\n",
      "   29 enough\n",
      "   29 worst\n",
      "   29 ear\n",
      "   29 being\n",
      "   28 does\n",
      "   28 case\n",
      "   28 movies\n",
      "   27 waste\n",
      "   27 off\n",
      "   27 these\n",
      "   27 right\n",
      "   27 say\n",
      "   27 came\n",
      "   27 got\n",
      "   27 am\n",
      "   27 two\n",
      "   27 amazing\n",
      "   26 thing\n",
      "   26 over\n",
      "   26 money\n",
      "   26 going\n",
      "   26 definitely\n",
      "   25 then\n",
      "   25 everything\n",
      "   25 minutes\n",
      "   25 her\n",
      "   24 doesnt\n",
      "   24 know\n",
      "   24 real\n",
      "   24 us\n",
      "   24 terrible\n",
      "   24 far\n",
      "   24 wonderful\n",
      "   23 cant\n",
      "   23 into\n",
      "   23 poor\n",
      "   23 many\n",
      "   23 new\n",
      "   23 look\n",
      "   23 give\n",
      "   23 people\n",
      "   23 wont\n",
      "   23 plot\n",
      "   23 films\n",
      "   22 both\n",
      "   22 piece\n",
      "   22 while\n",
      "   22 few\n",
      "   22 friendly\n",
      "   22 story\n",
      "   22 restaurant\n",
      "   21 anyone\n",
      "   21 worth\n",
      "   21 nothing\n",
      "   21 probably\n",
      "   21 experience\n",
      "   21 seen\n",
      "   20 times\n",
      "   20 highly\n",
      "   19 around\n",
      "   19 take\n",
      "   19 wasnt\n",
      "   19 screen\n",
      "   19 life\n",
      "   19 want\n",
      "   19 years\n",
      "   19 script\n",
      "   18 since\n",
      "   18 item\n",
      "   18 used\n",
      "   18 stars\n",
      "   18 quite\n",
      "   18 fine\n",
      "   18 easy\n",
      "   18 absolutely\n",
      "   18 loved\n",
      "   18 watching\n",
      "   18 delicious\n",
      "   17 horrible\n",
      "   17 went\n",
      "   17 worked\n",
      "   17 cool\n",
      "   17 night\n",
      "   17 find\n",
      "   17 totally\n",
      "   17 said\n",
      "   17 lot\n",
      "   17 happy\n",
      "   17 another\n",
      "   17 actors\n",
      "   17 show\n",
      "   17 staff\n",
      "   16 always\n",
      "   16 same\n",
      "   16 down\n",
      "   16 big\n",
      "   16 those\n",
      "   16 thought\n",
      "   16 long\n",
      "   16 she\n",
      "   16 should\n",
      "   16 such\n",
      "   16 ordered\n",
      "   16 family\n",
      "   16 awesome\n",
      "   16 character\n",
      "   16 eat\n",
      "   16 vegas\n",
      "   15 makes\n",
      "   15 things\n",
      "   15 before\n",
      "   15 awful\n",
      "   15 end\n",
      "   15 stupid\n",
      "   15 car\n",
      "   15 buy\n",
      "   15 talk\n",
      "   15 day\n",
      "   15 kind\n",
      "   15 though\n",
      "   15 small\n",
      "   15 music\n",
      "   15 funny\n",
      "   15 cast\n",
      "   15 perfect\n",
      "   14 impressed\n",
      "   14 actually\n",
      "   14 camera\n",
      "   14 comfortable\n",
      "   14 old\n",
      "   14 last\n",
      "   14 charger\n",
      "   14 part\n",
      "   14 couldnt\n",
      "   14 found\n",
      "   14 between\n",
      "   14 almost\n",
      "   14 line\n",
      "   14 fantastic\n",
      "   14 beautiful\n",
      "   14 scenes\n",
      "   14 watch\n",
      "   13 try\n",
      "   13 gets\n",
      "   13 slow\n",
      "   13 however\n",
      "   13 must\n",
      "   13 expect\n",
      "   13 black\n",
      "   13 come\n",
      "   13 each\n",
      "   13 especially\n",
      "   13 s\n",
      "   13 without\n",
      "   13 job\n",
      "   13 interesting\n",
      "   13 chicken\n",
      "   13 steak\n",
      "   12 charge\n",
      "   12 customer\n",
      "   12 bought\n",
      "   12 bluetooth\n",
      "   12 fit\n",
      "   12 $\n",
      "   12 anything\n",
      "   12 left\n",
      "   12 call\n",
      "   12 year\n",
      "   12 having\n",
      "   12 looks\n",
      "   12 calls\n",
      "   12 sure\n",
      "   12 cheap\n",
      "   12 id\n",
      "   12 problems\n",
      "   12 next\n",
      "   12 reception\n",
      "   12 performance\n",
      "   12 least\n",
      "   12 full\n",
      "   12 overall\n",
      "   12 perfectly\n",
      "   12 fast\n",
      "   12 order\n",
      "   12 hour\n",
      "   12 dialogue\n",
      "   12 man\n",
      "   12 pizza\n",
      "   12 sushi\n",
      "   11 disappointing\n",
      "   11 super\n",
      "   11 everyone\n",
      "   11 felt\n",
      "   11 put\n",
      "   11 plug\n",
      "   11 huge\n",
      "   11 bit\n",
      "   11 problem\n",
      "   11 clear\n",
      "   11 cell\n",
      "   11 ill\n",
      "   11 feel\n",
      "   11 working\n",
      "   11 barely\n",
      "   11 hear\n",
      "   11 may\n",
      "   11 where\n",
      "   11 away\n",
      "   11 hard\n",
      "   11 white\n",
      "   11 coming\n",
      "   11 different\n",
      "   11 bland\n",
      "   11 done\n",
      "   11 atmosphere\n",
      "   11 scene\n",
      "   11 ending\n",
      "   11 worse\n",
      "   11 special\n",
      "   11 liked\n",
      "   11 enjoyed\n",
      "   11 fresh\n",
      "   11 flavor\n",
      "   11 server\n",
      "   10 low\n",
      "   10 tried\n",
      "   10 getting\n",
      "   10 rather\n",
      "   10 deal\n",
      "   10 soon\n",
      "   10 once\n",
      "   10 using\n",
      "   10 started\n",
      "   10 tell\n",
      "   10 return\n",
      "   10 sucked\n",
      "   10 received\n",
      "   10 understand\n",
      "   10 avoid\n",
      "   10 through\n",
      "   10 thats\n",
      "   10 simply\n",
      "   10 play\n",
      "   10 )\n",
      "   10 incredible\n",
      "   10 enjoy\n",
      "   10 whole\n",
      "   10 gave\n",
      "   10 fact\n",
      "   10 saw\n",
      "   10 why\n",
      "   10 writing\n",
      "   10 art\n",
      "   10 buffet\n",
      "   10 salad\n",
      "   10 wait\n",
      "   10 burger\n",
      "   10 menu\n",
      "    9 either\n",
      "    9 three\n",
      "    9 stay\n",
      "    9 disappointment\n",
      "    9 believe\n",
      "    9 hours\n",
      "    9 unfortunately\n",
      "    9 looking\n",
      "    9 completely\n",
      "    9 crap\n",
      "    9 wanted\n",
      "    9 design\n",
      "    9 fits\n",
      "    9 own\n",
      "    9 easily\n",
      "    9 purchase\n",
      "    9 care\n",
      "    9 less\n",
      "    9 kept\n",
      "    9 face\n",
      "    9 truly\n",
      "    9 need\n",
      "    9 short\n",
      "    9 several\n",
      "    9 fun\n",
      "    9 mediocre\n",
      "    9 recommended\n",
      "    9 pleased\n",
      "    9 certainly\n",
      "    9 took\n",
      "    9 during\n",
      "    9 effects\n",
      "    9 game\n",
      "    9 watched\n",
      "    9 second\n",
      "    9 kids\n",
      "    9 feeling\n",
      "    9 director\n",
      "    9 taste\n",
      "    9 waited\n",
      "    9 prices\n",
      "    9 meal\n",
      "    8 wear\n",
      "    8 months\n",
      "    8 junk\n",
      "    8 plus\n",
      "    8 seriously\n",
      "    8 dropped\n",
      "    8 simple\n",
      "    8 motorola\n",
      "    8 strong\n",
      "    8 bar\n",
      "    8 theres\n",
      "    8 voice\n",
      "    8 guess\n",
      "    8 expected\n",
      "    8 together\n",
      "    8 cannot\n",
      "    8 hate\n",
      "    8 set\n",
      "    8 high\n",
      "    8 pictures\n",
      "    8 couple\n",
      "    8 trying\n",
      "    8 star\n",
      "    8 quick\n",
      "    8 seems\n",
      "    8 inside\n",
      "    8 friends\n",
      "    8 someone\n",
      "    8 yet\n",
      "    8 tv\n",
      "    8 predictable\n",
      "    8 wasted\n",
      "    8 half\n",
      "    8 amount\n",
      "    8 spot\n",
      "    8 rude\n",
      "    8 meat\n",
      "    8 selection\n",
      "    8 sauce\n",
      "    8 clean\n",
      "    8 overpriced\n",
      "    8 table\n",
      "    8 lunch\n",
      "    8 breakfast\n",
      "    7 oh\n",
      "    7 mention\n",
      "    7 color\n",
      "    7 useless\n",
      "    7 buttons\n",
      "    7 store\n",
      "    7 point\n",
      "    7 house\n",
      "    7 important\n",
      "    7 keep\n",
      "    7 might\n",
      "    7 wrong\n",
      "    7 comes\n",
      "    7 told\n",
      "    7 sucks\n",
      "    7 phones\n",
      "    7 software\n",
      "    7 volume\n",
      "    7 check\n",
      "    7 lost\n",
      "    7 pay\n",
      "    7 days\n",
      "    7 turn\n",
      "    7 cable\n",
      "    7 although\n",
      "    7 audio\n",
      "    7 review\n",
      "    7 original\n",
      "    7 word\n",
      "    7 device\n",
      "    7 area\n",
      "    7 under\n",
      "    7 arrived\n",
      "    7 wouldnt\n",
      "    7 else\n",
      "    7 hands\n",
      "    7 hot\n",
      "    7 top\n",
      "    7 glad\n",
      "    7 jabra\n",
      "    7 brilliant\n",
      "    7 outside\n",
      "    7 mess\n",
      "    7 human\n",
      "    7 actor\n",
      "    7 playing\n",
      "    7 waitress\n",
      "    7 itself\n",
      "    7 style\n",
      "    7 single\n",
      "    7 twice\n",
      "    7 cinema\n",
      "    7 played\n",
      "    7 heart\n",
      "    7 hope\n",
      "    7 cold\n",
      "    7 tasted\n",
      "    7 dishes\n",
      "    7 attentive\n",
      "    7 waiter\n",
      "    7 fries\n",
      "    6 none\n",
      "    6 ears\n",
      "    6 signal\n",
      "    6 difficult\n",
      "    6 within\n",
      "    6 weak\n",
      "    6 dead\n",
      "    6 nokia\n",
      "    6 zero\n",
      "    6 week\n",
      "    6 perhaps\n",
      "    6 extra\n",
      "    6 plastic\n",
      "    6 side\n",
      "    6 headsets\n",
      "    6 light\n",
      "    6 home\n",
      "    6 mind\n",
      "    6 obviously\n",
      "    6 series\n",
      "    6 walked\n",
      "    6 garbage\n",
      "    6 elsewhere\n",
      "    6 decent\n",
      "    6 places\n",
      "    6 room\n",
      "    6 amazon\n",
      "    6 extremely\n",
      "    6 free\n",
      "    6 charm\n",
      "    6 ago\n",
      "    6 authentic\n",
      "    6 exactly\n",
      "    6 range\n",
      "    6 whether\n",
      "    6 entire\n",
      "    6 joy\n",
      "    6 reasonable\n",
      "    6 setting\n",
      "    6 rating\n",
      "    6 boring\n",
      "    6 horror\n",
      "    6 lines\n",
      "    6 world\n",
      "    6 directing\n",
      "    6 considering\n",
      "    6 action\n",
      "    6 seeing\n",
      "    6 throughout\n",
      "    6 believable\n",
      "    6 him\n",
      "    6 looked\n",
      "    6 drive\n",
      "    6 john\n",
      "    6 possible\n",
      "    6 today\n",
      "    6 cinematography\n",
      "    6 history\n",
      "    6 sweet\n",
      "    6 served\n",
      "    6 dish\n",
      "    6 spicy\n",
      "    6 eating\n",
      "    6 cooked\n",
      "    6 tasty\n",
      "    6 management\n",
      "    6 sandwich\n",
      "    6 town\n",
      "    5 charging\n",
      "    5 lacking\n",
      "    5 basically\n",
      "    5 feels\n",
      "    5 poorly\n",
      "    5 hold\n",
      "    5 blue\n",
      "    5 %\n",
      "    5 literally\n",
      "    5 feature\n",
      "    5 picture\n",
      "    5 buying\n",
      "    5 headphones\n",
      "    5 until\n",
      "    5 unless\n",
      "    5 waiting\n",
      "    5 broke\n",
      "    5 verizon\n",
      "    5 sometimes\n",
      "    5 mostly\n",
      "    5 company\n",
      "    5 happened\n",
      "    5 unit\n",
      "    5 whatsoever\n",
      "    5 computer\n",
      "    5 bother\n",
      "    5 belt\n",
      "    5 above\n",
      "    5 bars\n",
      "    5 internet\n",
      "    5 rare\n",
      "    5 reason\n",
      "    5 wife\n",
      "    5 thin\n",
      "    5 ended\n",
      "    5 given\n",
      "    5 needed\n",
      "    5 quickly\n",
      "    5 holds\n",
      "    5 sides\n",
      "    5 helpful\n",
      "    5 large\n",
      "    5 others\n",
      "    5 note\n",
      "    5 wall\n",
      "    5 superb\n",
      "    5 finally\n",
      "    5 value\n",
      "    5 offers\n",
      "    5 priced\n",
      "    5 cases\n",
      "    5 leather\n",
      "    5 instead\n",
      "    5 youd\n",
      "    5 ask\n",
      "    5 owned\n",
      "    5 solid\n",
      "    5 clever\n",
      "    5 living\n",
      "    5 casting\n",
      "    5 ridiculous\n",
      "    5 whatever\n",
      "    5 sick\n",
      "    5 drama\n",
      "    5 rent\n",
      "    5 plain\n",
      "    5 lacks\n",
      "    5 hitchcock\n",
      "    5 annoying\n",
      "    5 written\n",
      "    5 girl\n",
      "    5 direction\n",
      "    5 pathetic\n",
      "    5 damn\n",
      "    5 average\n",
      "    5 leave\n",
      "    5 fish\n",
      "    5 myself\n",
      "    5 lead\n",
      "    5 empty\n",
      "    5 eyes\n",
      "    5 business\n",
      "    5 bring\n",
      "    5 close\n",
      "    5 (and\n",
      "    5 child\n",
      "    5 running\n",
      "    5 lovely\n",
      "    5 portrayal\n",
      "    5 subtle\n",
      "    5 sad\n",
      "    5 silent\n",
      "    5 warm\n",
      "    5 eaten\n",
      "    5 servers\n",
      "    5 shrimp\n",
      "    5 fried\n",
      "    5 anytime\n",
      "    5 beer\n",
      "    5 pasta\n",
      "    5 pho\n",
      "    5 seated\n",
      "    5 chips\n",
      "    5 seafood\n",
      "    5 portions\n",
      "    5 beef\n",
      "    5 ice\n",
      "    5 dessert\n",
      "    5 tender\n",
      "    4 weird\n",
      "    4 says\n",
      "    4 failed\n",
      "    4 red\n",
      "    4 mistake\n",
      "    4 advise\n",
      "    4 charged\n",
      "    4 unreliable\n",
      "    4 ability\n",
      "    4 isnt\n",
      "    4 break\n",
      "    4 plantronics\n",
      "    4 bt\n",
      "    4 clip\n",
      "    4 pair\n",
      "    4 likes\n",
      "    4 sending\n",
      "    4 despite\n",
      "    4 checked\n",
      "    4 turns\n",
      "    4 something\n",
      "    4 shipping\n",
      "    4 later\n",
      "    4 reading\n",
      "    4 front\n",
      "    4 player\n",
      "    4 form\n",
      "    4 goes\n",
      "    4 genuine\n",
      "    4 pull\n",
      "    4 trash\n",
      "    4 rated\n",
      "    4 impressive\n",
      "    4 fall\n",
      "    4 below\n",
      "    4 stuff\n",
      "    4 please\n",
      "    4 previous\n",
      "    4 clearly\n",
      "    4 third\n",
      "    4 gotten\n",
      "    4 missed\n",
      "    4 connection\n",
      "    4 lasts\n",
      "    4 disgusting\n",
      "    4 book\n",
      "    4 fairly\n",
      "    4 replace\n",
      "    4 able\n",
      "    4 moving\n",
      "    4 lightweight\n",
      "    4 recently\n",
      "    4 dirty\n",
      "    4 seem\n",
      "    4 costs\n",
      "    4 appearance\n",
      "    4 cute\n",
      "    4 sturdy\n",
      "    4 type\n",
      "    4 features\n",
      "    4 crisp\n",
      "    4 theyre\n",
      "    4 doing\n",
      "    4 hand\n",
      "    4 adorable\n",
      "    4 keyboard\n",
      "    4 strip\n",
      "    4 roles\n",
      "    4 total\n",
      "    4 youll\n",
      "    4 passed\n",
      "    4 beat\n",
      "    4 thumbs\n",
      "    4 graphics\n",
      "    4 incredibly\n",
      "    4 making\n",
      "    4 favorite\n",
      "    4 shots\n",
      "    4 wish\n",
      "    4 premise\n",
      "    4 theater\n",
      "    4 idea\n",
      "    4 complete\n",
      "    4 fails\n",
      "    4 editing\n",
      "    4 wow\n",
      "    4 seemed\n",
      "    4 torture\n",
      "    4 pretentious\n",
      "    4 visual\n",
      "    4 usual\n",
      "    4 depth\n",
      "    4 utterly\n",
      "    4 towards\n",
      "    4 beyond\n",
      "    4 minute\n",
      "    4 sense\n",
      "    4 stories\n",
      "    4 unbelievable\n",
      "    4 particularly\n",
      "    4 shot\n",
      "    4 space\n",
      "    4 mean\n",
      "    4 conclusion\n",
      "    4 imagination\n",
      "    4 words\n",
      "    4 chemistry\n",
      "    4 consider\n",
      "    4 already\n",
      "    4 suspense\n",
      "    4 arent\n",
      "    4 heard\n",
      "    4 gives\n",
      "    4 created\n",
      "    4 rate\n",
      "    4 reviews\n",
      "    4 fan\n",
      "    4 songs\n",
      "    4 often\n",
      "    4 budget\n",
      "    4 flick\n",
      "    4 lots\n",
      "    4 rolls\n",
      "    4 Â–\n",
      "    4 guy\n",
      "    4 joke\n",
      "    4 flat\n",
      "    4 attention\n",
      "    4 directors\n",
      "    4 rest\n",
      "    4 drago\n",
      "    4 youre\n",
      "    4 performances\n",
      "    4 dry\n",
      "    4 list\n",
      "    4 audience\n",
      "    4 ten\n",
      "    4 +\n",
      "    4 beginning\n",
      "    4 memorable\n",
      "    4 terrific\n",
      "    4 nasty\n",
      "    4 hilarious\n",
      "    4 role\n",
      "    4 enjoyable\n",
      "    4 deserves\n",
      "    4 appreciate\n",
      "    4 massive\n",
      "    4 sat\n",
      "    4 vibe\n",
      "    4 location\n",
      "    4 tables\n",
      "    4 ambiance\n",
      "    4 live\n",
      "    4 husband\n",
      "    4 drinks\n",
      "    4 tasteless\n",
      "    4 establishment\n",
      "    4 asked\n",
      "    4 needs\n",
      "    4 folks\n",
      "    4 dining\n",
      "    4 salmon\n",
      "    4 dinner\n",
      "    4 tacos\n",
      "    4 steaks\n",
      "    4 bread\n",
      "    4 bacon\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# printing out the frequency of word\n",
    "sorted_tokens = list(sorted(tok_count_dict, key=tok_count_dict.get, reverse=True))\n",
    "# filter out words that only appear less than 4 times\n",
    "vocab_list = [w for w in sorted_tokens if tok_count_dict[w] >= 4]\n",
    "\n",
    "for w in vocab_list:\n",
    "    print(\"%5d %s\" % (tok_count_dict[w], w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa7aaf2-d607-4bfb-982b-ab0107931c65",
   "metadata": {},
   "source": [
    "## Step3: Feature Extration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bccb3a1-427e-4629-9412-4510c85a5a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\arman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the original vacabulary list:\n",
      "4725\n",
      "The size of the first vacabulary list:\n",
      "55\n",
      "The size of the second vacabulary list:\n",
      "4602\n",
      "4572\n"
     ]
    }
   ],
   "source": [
    "sorted_tokens = list(sorted(tok_count_dict, key=tok_count_dict.get, reverse=True))\n",
    "\n",
    "# filter out the vocabulary that appears in just one time\n",
    "vocab_list_2 = [w for w in sorted_tokens if tok_count_dict[w] >= 1]\n",
    "\n",
    "# for first attempt, we tried to manualy built vocabulary list\n",
    "vocab_list = ['good', 'great', 'like', 'bad', 'best', 'love', 'excellent', 'better', 'recommend',\n",
    "              'nice', 'disappointed', 'pretty', 'worst', 'waste', 'amazing', 'terrible', 'wonderful',\n",
    "              'poor', 'friendly', 'loved', 'delicious', 'horrible', 'cool', 'happy', 'awesome', 'awful',\n",
    "              'stupid', 'perfect', 'impressed', 'comfortable', 'fantastic', 'beautiful', 'interesting',\n",
    "              'perfectly', 'disappointing', 'super', 'fast', 'problem', 'bland', 'worse', 'enjoyed', 'fresh',\n",
    "              'avoid', 'incredible', 'didn\\'t work', 'weird', 'useless', 'enjoy',\n",
    "              'sucked', 'disappointment', 'unfortunately', 'mediocre', 'recommended', 'pleased', 'junk']\n",
    "\n",
    "# for second try, we tried to import stopword from Natural Language Tool Kit\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "useless = stopwords.words('english')\n",
    "filtered_words = [word for word in vocab_list_2 if not word in useless]\n",
    "\n",
    "def remove_proper_nouns_nltk(tokens):\n",
    "    # POS tagging with NLTK\n",
    "    tagged_tokens = nltk.tag.pos_tag(tokens)\n",
    "\n",
    "    # Remove tokens that are proper nouns\n",
    "    edited_tokens = [word for word, tag in tagged_tokens if tag != 'NNP' and tag != 'NNPS']\n",
    "\n",
    "    return edited_tokens\n",
    "cleaned_text = remove_proper_nouns_nltk(filtered_words)\n",
    "\n",
    "# print out sizes\n",
    "print(\"The size of the original vacabulary list:\")\n",
    "print(len(sorted_tokens))\n",
    "\n",
    "\n",
    "print(\"The size of the first vacabulary list:\")\n",
    "print(len(vocab_list))\n",
    "\n",
    "print(\"The size of the second vacabulary list:\")\n",
    "print(len(filtered_words))\n",
    "print(len(cleaned_text))\n",
    "\n",
    "vocab_dict = dict()\n",
    "\n",
    "for vocab_id, tok in enumerate(cleaned_text):\n",
    "    vocab_dict[tok] = vocab_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30cc94-3b80-4826-9de4-28f491eafad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_preprocessor = CountVectorizer(binary=False, vocabulary=vocab_dict)\n",
    "\n",
    "bow_preprocessor.fit(tr_text_list)\n",
    "\n",
    "sparse_arr = bow_preprocessor.transform(tr_text_list)\n",
    "\n",
    "print(sparse_arr.shape)\n",
    "\n",
    "dense_arr_NV = sparse_arr.toarray()\n",
    "\n",
    "print(dense_arr_NV.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d750d6",
   "metadata": {},
   "source": [
    "## Step4: Create Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8c78c-a98b-4e55-b2a2-879b318effa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bow_classifier_pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('my_bow_feature_extractor',\n",
    "     CountVectorizer(min_df=1, max_df=1.0, ngram_range=(1, 1), vocabulary=vocab_dict, binary=False)),\n",
    "    ('my_classifier', sklearn.linear_model.LogisticRegression(C=1.0, max_iter=1000, random_state=101))\n",
    "])\n",
    "\n",
    "my_parameter_grid_by_name = dict()\n",
    "my_parameter_grid_by_name['my_bow_feature_extractor__min_df'] = [1, 2, 4]\n",
    "my_parameter_grid_by_name['my_classifier__C'] = np.logspace(-5, 5, 11)\n",
    "\n",
    "my_scoring_metric_name = 'accuracy'\n",
    "y_true = np.ravel(y_train_df)\n",
    "# print(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad477a1e",
   "metadata": {},
   "source": [
    "## Step5: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c46af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prng = np.random.RandomState(0)\n",
    "\n",
    "valid_ids = prng.choice(np.arange(N), size=800)\n",
    "\n",
    "valid_indicators_N = np.zeros(N)\n",
    "valid_indicators_N[valid_ids] = -1\n",
    "\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_N)\n",
    "\n",
    "grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "    my_bow_classifier_pipeline,\n",
    "    my_parameter_grid_by_name,\n",
    "    scoring=my_scoring_metric_name,\n",
    "    cv=my_splitter,\n",
    "    refit=False)\n",
    "\n",
    "grid_searcher.fit(tr_text_list, y_true)\n",
    "\n",
    "gsearch_results_df = pd.DataFrame(grid_searcher.cv_results_).copy()\n",
    "\n",
    "param_keys = ['param_my_bow_feature_extractor__min_df', 'param_my_classifier__C']\n",
    "\n",
    "# Rearrange row order so it is easy to skim\n",
    "gsearch_results_df.sort_values(param_keys, inplace=True)\n",
    "\n",
    "var = gsearch_results_df[param_keys + ['split0_test_score', 'rank_test_score']]\n",
    "\n",
    "print(var)\n",
    "\n",
    "# y_test_pred = np.ravel(test_text_list)\n",
    "# my_bow_classifier_pipeline.fit(tr_text_list, y_true)\n",
    "# result = my_bow_classifier_pipeline.predict(y_test_pred)\n",
    "#\n",
    "# print(result[:, np.newaxis])\n",
    "\n",
    "\n",
    "# print(yhat_tr_N[:,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe77c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ju-Hung's attempt\n",
    "train_ids, test_ids = cv.make_train_and_test_row_ids_for_n_fold_cv(len(y_true), random_state=8964)\n",
    "x_tr, y_tr = list(), list()\n",
    "x_va, y_va = list(), list()\n",
    "\n",
    "for index in train_ids[0]:\n",
    "    x_tr.append(tr_text_list[index])\n",
    "    y_tr.append(y_true[index])\n",
    "\n",
    "for index in test_ids[0]:\n",
    "    x_va.append(tr_text_list[index])\n",
    "    y_va.append(y_true[index])\n",
    "    \n",
    "ju_grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "    my_bow_classifier_pipeline,\n",
    "    my_parameter_grid_by_name,\n",
    "    scoring=my_scoring_metric_name,\n",
    "    refit=False)\n",
    "ju_grid_searcher.fit(x_tr, y_tr)\n",
    "gsearch_results_df = pd.DataFrame(ju_grid_searcher.cv_results_).copy()\n",
    "\n",
    "param_keys = ['param_my_bow_feature_extractor__min_df', 'param_my_classifier__C']\n",
    "\n",
    "# Rearrange row order so it is easy to skim\n",
    "gsearch_results_df.sort_values(param_keys, inplace=True)\n",
    "\n",
    "var = gsearch_results_df[param_keys + ['split0_test_score', 'rank_test_score']]\n",
    "\n",
    "print(var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3442d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('my_bow_feature_extractor', CountVectorizer(min_df=1, max_df=1.0, ngram_range=(1, 1), vocabulary=vocab_dict, binary=False)),\n",
    "    ('my_classifier', sklearn.linear_model.LogisticRegression(C=1.0, max_iter=1000, random_state=101))\n",
    "])\n",
    "\n",
    "best_train_pipeline.fit(x_tr, y_tr)\n",
    "yhat_tr_N = best_train_pipeline.predict_proba(x_tr)\n",
    "yhat_va_N = best_train_pipeline.predict_proba(x_va)\n",
    "plt.subplots(nrows=1, ncols=1, figsize=(5,5));\n",
    "fpr_tr, tpr_tr, th = sklearn.metrics.roc_curve(y_tr, yhat_tr_N[:, 1])\n",
    "fpr_va, tpr_va, th = sklearn.metrics.roc_curve(y_va, yhat_va_N[:, 1])\n",
    "roc_auc_tr = sklearn.metrics.auc(fpr_tr, tpr_tr)\n",
    "roc_auc_va = sklearn.metrics.auc(fpr_va, tpr_va)\n",
    "\n",
    "plt.plot(fpr_tr, tpr_tr, '.-', color='b', lw=2, label=f'Training Set (AUC = {roc_auc_tr:.2f})')\n",
    "plt.plot(fpr_va, tpr_va, '.-', color='r', lw=2, label=f'Validation Set (AUC = {roc_auc_va:.2f})')\n",
    "\n",
    "plt.title(\"ROC on Training set and Validation Set\");\n",
    "plt.xlabel('false positive rate');\n",
    "plt.ylabel('true positive rate');\n",
    "plt.legend(loc='lower right');\n",
    "B = 0.01\n",
    "\n",
    "plt.xlim([0 - B, 1 + B]);\n",
    "plt.ylim([0 - B, 1 + B]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480a396",
   "metadata": {},
   "source": [
    "## Step6: Hyperparameter Selection for Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ACC(ytrue_N, yhat_N):\n",
    "    # calling calculating function from above\n",
    "    TP, TN, FP, FN = calc_TP_TN_FP_FN(ytrue_N, yhat_N)\n",
    "    # defining denominator\n",
    "    de = TP + TN + FP + FN + 1e-10\n",
    "    # calculating accuracy\n",
    "    acc = (TP + TN) / de\n",
    "    return acc  # TODO fix me\n",
    "\n",
    "def calc_TP_TN_FP_FN(ytrue_N, yhat_N):\n",
    "    # Cast input to integer just to be sure we're getting what's expected\n",
    "    ytrue_N = np.asarray(ytrue_N, dtype=np.int32)\n",
    "    yhat_N = np.asarray(yhat_N, dtype=np.int32)\n",
    "\n",
    "    # TODO fix by calculating the number of true pos, true neg, etc.\n",
    "    TP = np.sum((ytrue_N == 1) & (yhat_N == 1))\n",
    "    TN = np.sum((ytrue_N == 0) & (yhat_N == 0))\n",
    "    FP = np.sum((ytrue_N == 0) & (yhat_N == 1))\n",
    "    FN = np.sum((ytrue_N == 1) & (yhat_N == 0))\n",
    "\n",
    "    # debug you\n",
    "    # print(TP, TN, FP, FN)\n",
    "    return TP.item(), TN.item(), FP.item(), FN.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4006a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('my_bow_feature_extractor', CountVectorizer(min_df=1, max_df=1.0, ngram_range=(1, 1), vocabulary=vocab_dict, binary=False)),\n",
    "    ('my_classifier', sklearn.linear_model.LogisticRegression(C=1.0, max_iter=1000, random_state=101))\n",
    "])\n",
    "\n",
    "best_train_pipeline.fit(tr_text_list, y_true)\n",
    "yhat_tr_N = best_train_pipeline.predict(tr_text_list)\n",
    "\n",
    "acc = np.round(calc_ACC(y_true, yhat_tr_N), 3)\n",
    "print(\"Acc of best pipe:\")\n",
    "print(acc)\n",
    "\n",
    "yhat_tr_N = best_train_pipeline.predict_proba(tr_text_list)\n",
    "plt.subplots(nrows=1, ncols=1, figsize=(5,5));\n",
    "fpr, tpr, th = sklearn.metrics.roc_curve(y_true, yhat_tr_N[:, 1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, '.-', color='b', lw=2, label=f'Model 1 (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.title(\"ROC on Whole Training Set\");\n",
    "plt.xlabel('false positive rate');\n",
    "plt.ylabel('true positive rate');\n",
    "plt.legend(loc='lower right');\n",
    "B = 0.01\n",
    "\n",
    "plt.xlim([0 - B, 1 + B]);\n",
    "plt.ylim([0 - B, 1 + B]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011bc83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_pipeline.fit(tr_text_list, y_true)\n",
    "\n",
    "my_valid_text_list = [tr_text_list[index] for index in valid_ids]\n",
    "print(my_valid_text_list)\n",
    "my_valid_true_list = [y_true[index] for index in valid_ids]\n",
    "print(my_valid_true_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48280e1",
   "metadata": {},
   "source": [
    "## Step7: Using the Best Pipeline to Predict the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832dcafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('my_bow_feature_extractor', CountVectorizer(min_df=1, max_df=1.0, ngram_range=(1, 1), vocabulary=vocab_dict, binary=False)),\n",
    "    ('my_classifier', sklearn.linear_model.LogisticRegression(C=1.0, max_iter=1000, random_state=101))\n",
    "])\n",
    "\n",
    "new_pipeline.fit(tr_text_list, y_true)\n",
    "yhat_tr_N = new_pipeline.predict(tr_text_list)\n",
    "acc = np.mean(y_true == yhat_tr_N)\n",
    "print(acc)\n",
    "\n",
    "yhat_test_N = new_pipeline.predict_proba(test_text_list)\n",
    "\n",
    "\n",
    "float_y_test = yhat_test_N[:,1]\n",
    "\n",
    "print(float_y_test)\n",
    "\n",
    "print(float_y_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb46180c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dca7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "\n",
    "def calc_confusion_matrix_for_probas_and_threshold(ytrue_N, yproba1_N, thr):\n",
    "    ytrue_N = np.asarray(ytrue_N, dtype=np.int32)\n",
    "    \n",
    "    # Determine hard predictions given probabilities\n",
    "    yproba1_N = np.asarray(yproba1_N, dtype=np.float64)\n",
    "    yhat_N = np.asarray(yproba1_N >= thr, dtype=np.int32)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(ytrue_N, yhat_N)\n",
    "    cm_df = pd.DataFrame(data=cm, columns=[0, 1], index=[0, 1])\n",
    "    cm_df.columns.name = 'Predicted'\n",
    "    cm_df.index.name = 'True'\n",
    "    return cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15816ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion = sklearn.metrics.confusion_matrix(y_train_df, yhat_tr_N)\n",
    "result = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=confusion)\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be4458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138870c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = list(np.where((yhat_tr_N == 1) & (y_true == 0))[0])\n",
    "FN = list(np.where((yhat_tr_N == 0) & (y_true == 1))[0])\n",
    "\n",
    "# debug you\n",
    "# print(yhat_tr_N)\n",
    "# print(y_true)\n",
    "# print(len(yhat_tr_N), len(y_true))\n",
    "# print(FP)\n",
    "# print(FN)\n",
    "FP_list = list()\n",
    "FN_list = list()\n",
    "\n",
    "rand_examples_FP = random.sample(FP, 10)\n",
    "rand_examples_FN = random.sample(FN, 10)\n",
    "# print(rand_5_examples_FP)\n",
    "\n",
    "\n",
    "for index in rand_examples_FP:\n",
    "    result = x_train_df['website_name'][index], x_train_df['text'][index]\n",
    "    FP_list.append(result)\n",
    "    \n",
    "for index in rand_examples_FN:\n",
    "    result = x_train_df['website_name'][index], x_train_df['text'][index]\n",
    "    FN_list.append(result)\n",
    "    \n",
    "print(\"False Positive Examples:\")\n",
    "for row in FP_list:\n",
    "    print('\\t'.join(row))\n",
    "    \n",
    "print()\n",
    "print(\"False Nagetive Examples:\")\n",
    "for row in FN_list:\n",
    "    print('\\t'.join(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ebe7f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arman\\.conda\\envs\\cs135_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\arman\\.conda\\envs\\cs135_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\arman\\.conda\\envs\\cs135_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\arman\\.conda\\envs\\cs135_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\arman\\.conda\\envs\\cs135_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.035255      0.010720         0.006786        0.002926   \n",
      "1        0.030145      0.002080         0.005638        0.004563   \n",
      "2        0.031815      0.002092         0.002731        0.003372   \n",
      "3        0.036311      0.008904         0.011518        0.004273   \n",
      "4        0.069382      0.060432         0.001005        0.002010   \n",
      "5        0.050242      0.002573         0.006014        0.002431   \n",
      "6        0.077364      0.017672         0.010031        0.008275   \n",
      "7        0.097767      0.006061         0.004723        0.006268   \n",
      "8        0.184241      0.016105         0.011907        0.004099   \n",
      "9        0.349434      0.036573         0.008938        0.008603   \n",
      "10       0.630996      0.048670         0.010988        0.004016   \n",
      "\n",
      "   param_my_bow_feature_extractor__min_df param_my_classifier__C  \\\n",
      "0                                       1                0.00001   \n",
      "1                                       1                 0.0001   \n",
      "2                                       1                  0.001   \n",
      "3                                       1                   0.01   \n",
      "4                                       1                    0.1   \n",
      "5                                       1                    1.0   \n",
      "6                                       1                   10.0   \n",
      "7                                       1                  100.0   \n",
      "8                                       1                 1000.0   \n",
      "9                                       1                10000.0   \n",
      "10                                      1               100000.0   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.787500   \n",
      "1   {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.785417   \n",
      "2   {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.785417   \n",
      "3   {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.793750   \n",
      "4   {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.804167   \n",
      "5   {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.835417   \n",
      "6   {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.808333   \n",
      "7   {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.795833   \n",
      "8   {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.775000   \n",
      "9   {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.756250   \n",
      "10  {'my_bow_feature_extractor__min_df': 1, 'my_cl...           0.754167   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0            0.741667           0.750000           0.745833   \n",
      "1            0.745833           0.627083           0.672917   \n",
      "2            0.745833           0.633333           0.672917   \n",
      "3            0.754167           0.656250           0.697917   \n",
      "4            0.781250           0.722917           0.756250   \n",
      "5            0.818750           0.772917           0.754167   \n",
      "6            0.812500           0.768750           0.743750   \n",
      "7            0.783333           0.745833           0.743750   \n",
      "8            0.752083           0.735417           0.733333   \n",
      "9            0.735417           0.729167           0.727083   \n",
      "10           0.729167           0.720833           0.714583   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.775000         0.760000        0.017989                5  \n",
      "1            0.720833         0.710417        0.055387               11  \n",
      "2            0.720833         0.711667        0.053532               10  \n",
      "3            0.729167         0.726250        0.047004                7  \n",
      "4            0.787500         0.770417        0.028303                3  \n",
      "5            0.789583         0.794167        0.029592                1  \n",
      "6            0.781250         0.782917        0.025529                2  \n",
      "7            0.764583         0.766667        0.020455                4  \n",
      "8            0.716667         0.742500        0.019747                6  \n",
      "9            0.679167         0.725417        0.025324                8  \n",
      "10           0.666667         0.717083        0.028577                9  \n",
      "   param_my_bow_feature_extractor__min_df param_my_classifier__C  \\\n",
      "0                                       1                0.00001   \n",
      "1                                       1                 0.0001   \n",
      "2                                       1                  0.001   \n",
      "3                                       1                   0.01   \n",
      "4                                       1                    0.1   \n",
      "5                                       1                    1.0   \n",
      "6                                       1                   10.0   \n",
      "7                                       1                  100.0   \n",
      "8                                       1                 1000.0   \n",
      "9                                       1                10000.0   \n",
      "10                                      1               100000.0   \n",
      "\n",
      "    split0_test_score  rank_test_score  \n",
      "0            0.787500                5  \n",
      "1            0.785417               11  \n",
      "2            0.785417               10  \n",
      "3            0.793750                7  \n",
      "4            0.804167                3  \n",
      "5            0.835417                1  \n",
      "6            0.808333                2  \n",
      "7            0.795833                4  \n",
      "8            0.775000                6  \n",
      "9            0.756250                8  \n",
      "10           0.754167                9  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_bow_classifier_pipeline_2 = sklearn.pipeline.Pipeline([\n",
    "    ('my_bow_feature_extractor',\n",
    "     CountVectorizer(min_df=1, max_df=1.0, ngram_range=(1, 1), vocabulary=vocab_dict, binary=False)),\n",
    "    ('my_classifier', sklearn.linear_model.LogisticRegression(C=1.0, max_iter=1000, random_state=101))\n",
    "])\n",
    "\n",
    "my_parameter_grid_by_name_2 = dict()\n",
    "my_parameter_grid_by_name_2['my_bow_feature_extractor__min_df'] = [1]\n",
    "my_parameter_grid_by_name_2['my_classifier__C'] = np.logspace(-5, 5, 11)\n",
    "\n",
    "my_scoring_metric_name = 'accuracy'\n",
    "y_true = np.ravel(y_train_df)\n",
    "# print(y_true)\n",
    "\n",
    "\n",
    "\n",
    "grid_searcher_2 = sklearn.model_selection.GridSearchCV(\n",
    "    my_bow_classifier_pipeline_2,\n",
    "    my_parameter_grid_by_name_2,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    refit=False)\n",
    "\n",
    "grid_searcher_2.fit(tr_text_list, y_true)\n",
    "\n",
    "gsearch_results_df_2 = pd.DataFrame(grid_searcher_2.cv_results_).copy()\n",
    "\n",
    "param_keys = ['param_my_bow_feature_extractor__min_df', 'param_my_classifier__C']\n",
    "print(gsearch_results_df_2)\n",
    "# Rearrange row order so it is easy to skim\n",
    "gsearch_results_df_2.sort_values(param_keys, inplace=True)\n",
    "\n",
    "var_2 = gsearch_results_df_2[param_keys + ['split0_test_score', 'rank_test_score']]\n",
    "\n",
    "print(var_2)\n",
    "\n",
    "plt.plot(gsearch_results_df_2['param_my_classifier__C'], gsearch_results_df_2['mean_test_score'], '.-', color='b', lw=2)\n",
    "# plt.plot(fpr_va, tpr_va, '.-', color='r', lw=2, label=f'Validation Set (AUC = {roc_auc_va:.2f})')\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "\n",
    "plt.title(\"ROC on Training set and Validation Set\");\n",
    "plt.xlabel('Hyperparameter C');\n",
    "plt.ylabel('Accuracy Rate');\n",
    "plt.legend(loc='lower right');\n",
    "B = 0.01\n",
    "\n",
    "\n",
    "# plt.xlim([0 - B, 1 + B]);\n",
    "plt.ylim([0 - B, 1 + B]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1ba2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
